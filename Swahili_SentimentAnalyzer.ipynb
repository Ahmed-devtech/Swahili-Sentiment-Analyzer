{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf380fe0",
   "metadata": {},
   "source": [
    "This is an Natural Language processing Project. A swahili sentiment analyzer. which uses the swahili sentiment analysis dataset from github https://github.com/Neurotech-HQ/swahili-sentiment-analysis-dataset. This project also uses a custom swahili stopwords csv file from the \"Enhancing text pre-processing for Swahili language: Datasets for common Swahili stop-words, slangs and typos with equivalent proper words\" research article by Bernard Masua and Noel Masasi. The code preprocesses the data by removing the noise. Feature extraction using countvectorizer. It then trains the model using the naive bayes classifier algorithm to classify the texts into the sentiment categories.It then uses the gradio library to deploy the NLP application. The code launches the Gradio interface where you can input Swahili text and get the sentiment analysis result as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef561de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\gradio\\inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gradio as gr\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Load the custom list of stop words from a CSV file\n",
    "    stopwords_df = pd.read_csv('Common Swahili Stop-words.csv')\n",
    "    stopwords = set(stopwords_df['StopWords'].tolist() + list(string.punctuation))\n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "    # Join the tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "def extract_features(texts):\n",
    "    # Preprocess the texts\n",
    "    preprocessed_texts = [preprocess(text) for text in texts]\n",
    "    # Extract features using CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(preprocessed_texts)\n",
    "    return X, vectorizer\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Load the training data\n",
    "    data = pd.read_csv('swahili.csv')\n",
    "    X_train = data['text']\n",
    "    y_train = data['sentiment']\n",
    "    # Extract features from the training data\n",
    "    X_train_features, vectorizer = extract_features(X_train)\n",
    "    # Train a Naive Bayes classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_features, y_train)\n",
    "    return clf, vectorizer\n",
    "\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "clf, vectorizer = train_model()\n",
    "\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess(text)\n",
    "    # Extract features using the vectorizer\n",
    "    X = vectorizer.transform([preprocessed_text])\n",
    "    # Make a prediction\n",
    "    y_pred = clf.predict_proba(X)[0]\n",
    "    # Assign the sentiment label based on the prediction\n",
    "    if y_pred[0] > y_pred[1]:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "# Define the input and output interfaces\n",
    "input_text = gr.inputs.Textbox(label=\"Enter a Swahili text\")\n",
    "output_text = gr.outputs.Textbox(label=\"Sentiment\")\n",
    "\n",
    "# Define the function to be used as the backend\n",
    "def predict(input):\n",
    "    return predict_sentiment(input)\n",
    "\n",
    "# Create the interface\n",
    "iface = gr.Interface(fn=predict, inputs=input_text, outputs=output_text, title=\"Swahili Sentiment Analysis\")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99ef94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18e0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
